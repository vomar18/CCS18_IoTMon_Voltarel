{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb2f531",
   "metadata": {},
   "source": [
    "# ## second clustering approach: pair of keywords \n",
    "since that I use a new app dataset (that is the union of the Official Samsung SmartThings: https://github.com/vomar18/SmartThingsPublic and the nsslabcuus: https://github.com/nsslabcuus/IoTMon)\n",
    "1. check every single app description in order to identify:\"The entity keyword with the highest aggregated value is considered as a representative keyword for the cluster\"\n",
    "2. create the distance and then the similarity matrix\n",
    "3. save the pair of word with the highest aggregation value (over than 90%??)\n",
    "4. save the result inside: \"analysis_NEW/physical_channel_2.JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637d2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!attention!! use python 3.6 for manage the packet stanza that is \n",
    "# the Official Stanford NLP Python Library for Many Human Languages\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors \n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist # for the Manhattan distance\n",
    "import json   # for read the JSON file\n",
    "import stanza # Official Stanford NLP Python Library for Many Human Languages\n",
    "import re     # for preprocessing the descriptions (necessary for using the word2vec)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5a6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read only descriptions and save them\n",
    "descriptions = [] #array with descriptions\n",
    "with open(\"\", \"r\") as read_file: # load the JSON file with app descriptions\n",
    "    app_descriptions = json.load(read_file)\n",
    "\n",
    "for i in app_descriptions:\n",
    "    descriptions.append(app_descriptions[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a992d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total app description found: 129\n"
     ]
    }
   ],
   "source": [
    "print(\"total app description found: \"+ str(len(descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b79152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fbc1ac58bc48fa8c2b73d64fac802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-17 08:18:44 INFO: Downloading default packages for language: en (English)...\n",
      "2021-09-17 08:18:46 INFO: File exists: /home/volta/stanza_resources/en/default.zip.\n",
      "2021-09-17 08:18:51 INFO: Finished downloading models and saved to /home/volta/stanza_resources.\n",
      "2021-09-17 08:18:51 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-09-17 08:18:51 INFO: Use device: cpu\n",
      "2021-09-17 08:18:51 INFO: Loading: tokenize\n",
      "2021-09-17 08:18:51 INFO: Loading: pos\n",
      "2021-09-17 08:18:52 INFO: Loading: lemma\n",
      "2021-09-17 08:18:52 INFO: Loading: depparse\n",
      "2021-09-17 08:18:52 INFO: Loading: sentiment\n",
      "2021-09-17 08:18:53 INFO: Loading: ner\n",
      "2021-09-17 08:18:53 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en')       # This downloads the English models for the neural pipeline\n",
    "nlp = stanza.Pipeline('en') # This sets up a default neural pipeline in English\n",
    "model = KeyedVectors.load_word2vec_format('/home/volta/Documenti/CCS18_CS/word2vec/GoogleNews-vectors-negative300.bin', binary=True, limit=100000) # load word2vec pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeec2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysing app description:  0\n",
      "word:graph\n",
      "['graph']\n",
      "analysing app description:  1\n",
      "word:thermostat\n",
      "word:everything\n",
      "['thermostat', 'everything']\n",
      "analysing app description:  2\n",
      "word:Home\n",
      "word:phrase\n",
      "word:door\n",
      "word:region\n",
      "['home', 'phrase', 'door', 'region']\n",
      "analysing app description:  3\n",
      "word:humidity\n",
      "word:threshold\n",
      "word:switch\n",
      "['humidity', 'threshold', 'switch']\n",
      "analysing app description:  4\n",
      "analysing app description:  5\n",
      "analysing app description:  6\n",
      "word:set\n",
      "word:Presence\n",
      "word:mode\n",
      "word:change\n",
      "word:everyone\n",
      "word:conjunction\n",
      "word:Turn\n",
      "word:thermostat\n",
      "word:security\n",
      "['set', 'presence', 'mode', 'change', 'everyone', 'conjunction', 'turn', 'thermostat', 'security']\n",
      "analysing app description:  7\n",
      "word:motion\n",
      "['motion']\n",
      "analysing app description:  8\n",
      "word:place\n",
      "word:home\n",
      "['place', 'home']\n",
      "analysing app description:  9\n",
      "word:sensor\n",
      "word:space\n",
      "['sensor', 'space']\n",
      "analysing app description:  10\n",
      "word:Control\n",
      "['control']\n",
      "analysing app description:  11\n",
      "word:power\n",
      "word:time\n",
      "['power', 'time']\n",
      "analysing app description:  12\n",
      "analysing app description:  13\n",
      "word:carpooling\n",
      "word:person\n",
      "word:notification\n",
      "['carpooling', 'person', 'notification']\n",
      "analysing app description:  14\n",
      "word:valve\n",
      "word:moisture\n",
      "word:SMS\n",
      "word:notification\n",
      "['valve', 'moisture', 'sms', 'notification']\n",
      "analysing app description:  15\n",
      "word:light\n",
      "['light']\n",
      "analysing app description:  16\n",
      "word:outlet\n",
      "word:user\n",
      "word:period\n",
      "word:time\n",
      "['outlet', 'user', 'period', 'time']\n",
      "analysing app description:  17\n",
      "word:period\n",
      "word:motion\n",
      "['period', 'motion']\n",
      "analysing app description:  18\n",
      "word:controller\n",
      "word:location\n",
      "word:order\n",
      "word:Device\n",
      "['controller', 'location', 'order', 'device']\n",
      "analysing app description:  19\n",
      "word:number\n",
      "word:switch\n",
      "word:row\n",
      "['number', 'switch', 'row']\n",
      "analysing app description:  20\n",
      "word:moisture\n",
      "word:sensor\n",
      "word:input\n",
      "['moisture', 'sensor', 'input']\n",
      "analysing app description:  21\n",
      "word:time\n",
      "word:cabinet\n",
      "word:door\n",
      "word:set\n",
      "word:schedule\n",
      "['time', 'cabinet', 'door', 'set', 'schedule']\n",
      "analysing app description:  22\n",
      "word:motion\n",
      "word:bedroom\n",
      "word:bathroom\n",
      "word:night\n",
      "word:occupant\n",
      "word:period\n",
      "word:time\n",
      "['motion', 'bedroom', 'bathroom', 'night', 'occupant', 'period', 'time']\n",
      "analysing app description:  23\n",
      "word:energy\n",
      "['energy']\n",
      "analysing app description:  24\n",
      "word:energy\n",
      "['energy']\n",
      "analysing app description:  25\n",
      "word:element\n",
      "word:demonstration\n",
      "word:app\n",
      "['element', 'demonstration', 'app']\n",
      "analysing app description:  26\n",
      "word:schedule\n",
      "word:pet\n",
      "word:food\n",
      "word:feeder\n",
      "word:app\n",
      "word:time\n",
      "word:life\n",
      "['schedule', 'pet', 'food', 'feeder', 'app', 'time', 'life']\n",
      "analysing app description:  27\n",
      "word:push\n",
      "word:notification\n",
      "word:text\n",
      "word:message\n",
      "word:water\n",
      "['push', 'notification', 'text', 'message', 'water']\n",
      "analysing app description:  28\n",
      "word:something\n",
      "word:grace\n",
      "word:period\n",
      "word:presence\n",
      "['something', 'grace', 'period', 'presence']\n",
      "analysing app description:  29\n",
      "word:garage\n",
      "word:door\n",
      "word:text\n",
      "word:message\n",
      "['garage', 'door', 'text', 'message']\n",
      "analysing app description:  30\n",
      "word:garage\n",
      "word:door\n",
      "word:switch\n",
      "['garage', 'door', 'switch']\n",
      "analysing app description:  31\n",
      "analysing app description:  32\n",
      "word:app\n",
      "['app']\n",
      "analysing app description:  33\n",
      "word:endpoint\n",
      "word:user\n",
      "word:environment\n",
      "['endpoint', 'user', 'environment']\n",
      "analysing app description:  34\n",
      "word:motion\n",
      "word:time\n",
      "word:night\n",
      "['motion', 'time', 'night']\n",
      "analysing app description:  35\n",
      "word:set\n",
      "word:presence\n",
      "word:mode\n",
      "word:change\n",
      "word:someone\n",
      "word:home\n",
      "['set', 'presence', 'mode', 'change', 'someone', 'home']\n",
      "analysing app description:  36\n",
      "word:something\n",
      "word:day\n",
      "word:text\n",
      "word:message\n",
      "['something', 'day', 'text', 'message']\n",
      "analysing app description:  37\n",
      "word:schedule\n",
      "word:pet\n",
      "word:food\n",
      "word:feeder\n",
      "word:app\n",
      "word:time\n",
      "word:life\n",
      "['schedule', 'pet', 'food', 'feeder', 'app', 'time', 'life']\n",
      "analysing app description:  38\n",
      "word:set\n",
      "word:presence\n",
      "word:home\n",
      "word:status\n",
      "word:change\n",
      "word:sun\n",
      "word:state\n",
      "word:occupancy\n",
      "['set', 'presence', 'home', 'status', 'change', 'sun', 'state', 'occupancy']\n",
      "analysing app description:  39\n",
      "word:IP\n",
      "word:hub\n",
      "handling Error:  \"Key 'ip' not present\"\n",
      "['hub']\n",
      "analysing app description:  40\n",
      "word:brightness\n",
      "word:level\n",
      "word:Hue\n",
      "word:mood\n",
      "['brightness', 'level', 'hue', 'mood']\n",
      "analysing app description:  41\n",
      "word:text\n",
      "word:movement\n",
      "['text', 'movement']\n",
      "analysing app description:  42\n",
      "word:temperature\n",
      "word:setting\n",
      "word:text\n",
      "word:heater\n",
      "word:appliance\n",
      "['temperature', 'setting', 'text', 'heater', 'appliance']\n",
      "analysing app description:  43\n",
      "word:temperature\n",
      "word:setting\n",
      "word:notification\n",
      "word:A/C\n",
      "word:unit\n",
      "word:fan\n",
      "handling Error:  \"Key 'a/c' not present\"\n",
      "['temperature', 'setting', 'notification', 'unit', 'fan']\n",
      "analysing app description:  44\n",
      "word:Jawbone\n",
      "word:button\n",
      "['jawbone', 'button']\n",
      "analysing app description:  45\n",
      "word:state\n",
      "['state']\n",
      "analysing app description:  46\n",
      "word:thermostat\n",
      "word:response\n",
      "word:mode\n",
      "word:change\n",
      "word:energy\n",
      "word:money\n",
      "['thermostat', 'response', 'mode', 'change', 'energy', 'money']\n",
      "analysing app description:  47\n",
      "word:temperature\n",
      "word:sensor\n",
      "word:space\n",
      "word:thermostat\n",
      "word:time\n",
      "['temperature', 'sensor', 'space', 'thermostat', 'time']\n",
      "analysing app description:  48\n",
      "word:message\n",
      "word:light\n",
      "word:laundry\n",
      "['message', 'light', 'laundry']\n",
      "analysing app description:  49\n",
      "word:door\n",
      "word:window\n",
      "word:amount\n",
      "word:time\n",
      "['door', 'window', 'amount', 'time']\n",
      "analysing app description:  50\n",
      "word:Multi\n",
      "['multi']\n",
      "analysing app description:  51\n",
      "word:Contact\n",
      "word:Sensor\n",
      "['contact', 'sensor']\n",
      "analysing app description:  52\n",
      "word:Service\n",
      "word:Manager\n",
      "['service', 'manager']\n",
      "analysing app description:  53\n",
      "word:motion\n",
      "word:period\n",
      "word:time\n",
      "['motion', 'period', 'time']\n",
      "analysing app description:  54\n",
      "word:motion\n",
      "word:door\n",
      "word:illuminance\n",
      "handling Error:  \"Key 'illuminance' not present\"\n",
      "['motion', 'door']\n",
      "analysing app description:  55\n",
      "word:sensor\n",
      "['sensor']\n",
      "analysing app description:  56\n",
      "analysing app description:  57\n",
      "word:door\n",
      "word:time\n",
      "word:Option\n",
      "word:contact\n",
      "word:sensor\n",
      "['door', 'time', 'option', 'contact', 'sensor']\n",
      "analysing app description:  58\n",
      "word:deadbolt\n",
      "word:lever\n",
      "word:lock\n",
      "word:Presence\n",
      "word:tag\n",
      "word:smartphone\n",
      "word:location\n",
      "handling Error:  \"Key 'deadbolt' not present\"\n",
      "['lever', 'lock', 'presence', 'tag', 'smartphone', 'location']\n",
      "analysing app description:  59\n",
      "word:text\n",
      "word:mail\n",
      "word:mailbox\n",
      "word:Multi\n",
      "word:door\n",
      "word:Note\n",
      "word:battery\n",
      "word:life\n",
      "['text', 'mail', 'mailbox', 'multi', 'door', 'note', 'battery', 'life']\n",
      "analysing app description:  60\n",
      "word:set\n",
      "word:thermostat\n",
      "word:mode\n",
      "word:change\n",
      "word:setpoint\n",
      "word:app\n",
      "word:state\n",
      "handling Error:  \"Key 'setpoint' not present\"\n",
      "['set', 'thermostat', 'mode', 'change', 'app', 'state']\n",
      "analysing app description:  61\n",
      "word:app\n",
      "word:ambient\n",
      "word:light\n",
      "word:notification\n",
      "word:drawer\n",
      "word:cabinet\n",
      "word:reminder\n",
      "word:time\n",
      "word:day\n",
      "word:draw\n",
      "word:message\n",
      "word:LED\n",
      "['app', 'ambient', 'light', 'notification', 'drawer', 'cabinet', 'reminder', 'time', 'day', 'draw', 'message', 'led']\n",
      "analysing app description:  62\n",
      "word:reminder\n",
      "word:medicine\n",
      "word:cabinet\n",
      "word:drawer\n",
      "word:time\n",
      "word:notification\n",
      "word:text\n",
      "word:message\n",
      "['reminder', 'medicine', 'cabinet', 'drawer', 'time', 'notification', 'text', 'message']\n",
      "analysing app description:  63\n",
      "word:Hue\n",
      "['hue']\n",
      "analysing app description:  64\n",
      "word:lighting\n",
      "word:cube\n",
      "['lighting', 'cube']\n",
      "analysing app description:  65\n",
      "word:toggling\n",
      "word:switch\n",
      "word:lock\n",
      "word:garage\n",
      "word:door\n",
      "word:Tag\n",
      "word:touch\n",
      "word:event\n",
      "handling Error:  \"Key 'toggling' not present\"\n",
      "['switch', 'lock', 'garage', 'door', 'tag', 'touch', 'event']\n",
      "analysing app description:  66\n",
      "word:anything\n",
      "word:home\n",
      "['anything', 'home']\n",
      "analysing app description:  67\n",
      "word:push\n",
      "word:message\n",
      "word:phone\n",
      "word:sensor\n",
      "['push', 'message', 'phone', 'sensor']\n",
      "analysing app description:  68\n",
      "word:color\n",
      "word:brightness\n",
      "word:Hue\n",
      "word:variety\n",
      "word:motion\n",
      "word:contact\n",
      "word:acceleration\n",
      "word:moisture\n",
      "word:presence\n",
      "['color', 'brightness', 'hue', 'variety', 'motion', 'contact', 'acceleration', 'moisture', 'presence']\n",
      "analysing app description:  69\n",
      "word:time\n",
      "['time']\n",
      "analysing app description:  70\n",
      "word:Test\n",
      "word:app\n",
      "word:end\n",
      "['test', 'app', 'end']\n",
      "analysing app description:  71\n",
      "word:burst\n",
      "word:push\n",
      "word:notification\n",
      "['burst', 'push', 'notification']\n",
      "analysing app description:  72\n",
      "word:energy\n",
      "word:time\n",
      "word:appliance\n",
      "word:curling\n",
      "word:iron\n",
      "word:TV\n",
      "word:use\n",
      "word:switch\n",
      "word:number\n",
      "['energy', 'time', 'appliance', 'curling', 'iron', 'tv', 'use', 'switch', 'number']\n",
      "analysing app description:  73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:push\n",
      "word:notification\n",
      "word:Presence\n",
      "word:tag\n",
      "word:smartphone\n",
      "word:location\n",
      "['push', 'notification', 'presence', 'tag', 'smartphone', 'location']\n",
      "analysing app description:  74\n",
      "word:text\n",
      "word:message\n",
      "word:presence\n",
      "word:status\n",
      "['text', 'message', 'presence', 'status']\n",
      "analysing app description:  75\n",
      "word:inclement\n",
      "word:weather\n",
      "handling Error:  \"Key 'inclement' not present\"\n",
      "['weather']\n",
      "analysing app description:  76\n",
      "word:arrival\n",
      "word:departure\n",
      "word:car\n",
      "word:door\n",
      "word:N\n",
      "word:motion\n",
      "word:interior\n",
      "word not processed:  n\n",
      "['arrival', 'departure', 'car', 'door', 'motion', 'interior']\n",
      "analysing app description:  77\n",
      "word:someone\n",
      "word:time\n",
      "word:morning\n",
      "['someone', 'time', 'morning']\n",
      "analysing app description:  78\n",
      "word:time\n",
      "word:day\n",
      "['time', 'day']\n",
      "analysing app description:  79\n",
      "word:push\n",
      "word:notification\n",
      "word:weather\n",
      "word:area\n",
      "['push', 'notification', 'weather', 'area']\n",
      "analysing app description:  80\n",
      "word:mode\n",
      "word:candle\n",
      "word:lighting\n",
      "word:havdalah\n",
      "word:API\n",
      "word:shabbat\n",
      "word:chag\n",
      "word:time\n",
      "handling Error:  \"Key 'havdalah' not present\"\n",
      "handling Error:  \"Key 'api' not present\"\n",
      "handling Error:  \"Key 'shabbat' not present\"\n",
      "handling Error:  \"Key 'chag' not present\"\n",
      "['mode', 'candle', 'lighting', 'time']\n",
      "analysing app description:  81\n",
      "word:Control\n",
      "word:place\n",
      "word:home\n",
      "['control', 'place', 'home']\n",
      "analysing app description:  82\n",
      "word:Panic\n",
      "word:Button\n",
      "['panic', 'button']\n",
      "analysing app description:  83\n",
      "word:sleep\n",
      "word:mode\n",
      "word:house\n",
      "word:bed\n",
      "word:morning\n",
      "word:button\n",
      "word:UP\n",
      "['sleep', 'mode', 'house', 'bed', 'morning', 'button', 'up']\n",
      "analysing app description:  84\n",
      "word:alarm\n",
      "word:panel\n",
      "word:security\n",
      "word:light\n",
      "word:notification\n",
      "word:text\n",
      "word:message\n",
      "word:location\n",
      "word:mode\n",
      "['alarm', 'panel', 'security', 'light', 'notification', 'text', 'message', 'location', 'mode']\n",
      "analysing app description:  85\n",
      "word:chat\n",
      "word:mod\n",
      "['chat', 'mod']\n",
      "analysing app description:  86\n",
      "word:time\n",
      "word:cabinet\n",
      "word:door\n",
      "word:set\n",
      "word:schedule\n",
      "['time', 'cabinet', 'door', 'set', 'schedule']\n",
      "analysing app description:  87\n",
      "word:motion\n",
      "word:bedroom\n",
      "word:bathroom\n",
      "word:night\n",
      "word:occupant\n",
      "word:period\n",
      "word:time\n",
      "['motion', 'bedroom', 'bathroom', 'night', 'occupant', 'period', 'time']\n",
      "analysing app description:  88\n",
      "word:schedule\n",
      "word:home\n",
      "word:ventilation\n",
      "['schedule', 'home', 'ventilation']\n",
      "analysing app description:  89\n",
      "word:humidifier\n",
      "word:humidity\n",
      "word:sensor\n",
      "handling Error:  \"Key 'humidifier' not present\"\n",
      "['humidity', 'sensor']\n",
      "analysing app description:  90\n",
      "word:motion\n",
      "word:light\n",
      "word:time\n",
      "['motion', 'light', 'time']\n",
      "analysing app description:  91\n",
      "word:glass\n",
      "word:water\n",
      "word:middle\n",
      "word:night\n",
      "['glass', 'water', 'middle', 'night']\n",
      "analysing app description:  92\n",
      "word:device\n",
      "word:time\n",
      "word:week\n",
      "word:person\n",
      "['device', 'time', 'week', 'person']\n",
      "analysing app description:  93\n",
      "word:Weather\n",
      "word:Tile\n",
      "word:hour\n",
      "['weather', 'tile', 'hour']\n",
      "analysing app description:  94\n",
      "word:song\n",
      "word:station\n",
      "word:mode\n",
      "['song', 'station', 'mode']\n",
      "analysing app description:  95\n",
      "word:system\n",
      "['system']\n",
      "analysing app description:  96\n",
      "word:Speaker\n",
      "word:place\n",
      "word:home\n",
      "['speaker', 'place', 'home']\n",
      "analysing app description:  97\n",
      "word:song\n",
      "word:station\n",
      "['song', 'station']\n",
      "analysing app description:  98\n",
      "word:sound\n",
      "word:message\n",
      "word:Speaker\n",
      "word:mode\n",
      "['sound', 'message', 'speaker', 'mode']\n",
      "analysing app description:  99\n",
      "word:weather\n",
      "word:report\n",
      "word:Speaker\n",
      "word:mode\n",
      "['weather', 'report', 'speaker', 'mode']\n",
      "analysing app description:  100\n",
      "word:Control\n",
      "word:period\n",
      "word:time\n",
      "word:number\n",
      "word:hour\n",
      "['control', 'period', 'time', 'number', 'hour']\n",
      "analysing app description:  101\n",
      "word:Setup\n",
      "word:Spruce\n",
      "word:irrigation\n",
      "word:controller\n",
      "['setup', 'spruce', 'irrigation', 'controller']\n",
      "analysing app description:  102\n",
      "word:step\n",
      "word:tracker\n",
      "word:device\n",
      "['step', 'tracker', 'device']\n",
      "analysing app description:  103\n",
      "word:mode\n",
      "word:sunrise\n",
      "word:sunset\n",
      "['mode', 'sunrise', 'sunset']\n",
      "analysing app description:  104\n",
      "word:Home\n",
      "word:phrase\n",
      "word:mode\n",
      "word:switch\n",
      "word:state\n",
      "word:use\n",
      "['home', 'phrase', 'mode', 'switch', 'state', 'use']\n",
      "analysing app description:  105\n",
      "word:mode\n",
      "word:switch\n",
      "word:state\n",
      "word:use\n",
      "['mode', 'switch', 'state', 'use']\n",
      "analysing app description:  106\n",
      "word:waking\n",
      "word:speaker\n",
      "word:alarm\n",
      "['waking', 'speaker', 'alarm']\n",
      "analysing app description:  107\n",
      "word:text\n",
      "word:message\n",
      "word:phone\n",
      "word:sensor\n",
      "['text', 'message', 'phone', 'sensor']\n",
      "analysing app description:  108\n",
      "word:text\n",
      "word:message\n",
      "word:motion\n",
      "['text', 'message', 'motion']\n",
      "analysing app description:  109\n",
      "word:collection\n",
      "word:state\n",
      "word:switch\n",
      "['collection', 'state', 'switch']\n",
      "analysing app description:  110\n",
      "word:set\n",
      "word:response\n",
      "word:motion\n",
      "word:event\n",
      "word:switch\n",
      "['set', 'response', 'motion', 'event', 'switch']\n",
      "analysing app description:  111\n",
      "word:text\n",
      "word:gun\n",
      "word:case\n",
      "['text', 'gun', 'case']\n",
      "analysing app description:  112\n",
      "word:anything\n",
      "word:home\n",
      "['anything', 'home']\n",
      "analysing app description:  113\n",
      "word:switch\n",
      "['switch']\n",
      "analysing app description:  114\n",
      "word:something\n",
      "['something']\n",
      "analysing app description:  115\n",
      "word:something\n",
      "word:sensor\n",
      "['something', 'sensor']\n",
      "analysing app description:  116\n",
      "word:something\n",
      "word:sunset\n",
      "word:anytime\n",
      "['something', 'sunset', 'anytime']\n",
      "analysing app description:  117\n",
      "word:Ubi\n",
      "word:device\n",
      "word:Account\n",
      "handling Error:  \"Key 'ubi' not present\"\n",
      "['device', 'account']\n",
      "analysing app description:  118\n",
      "word:Warning\n",
      "['warning']\n",
      "analysing app description:  119\n",
      "word:door\n",
      "word:location\n",
      "['door', 'location']\n",
      "analysing app description:  120\n",
      "analysing app description:  121\n",
      "word:space\n",
      "word:heater\n",
      "word:window\n",
      "word:air\n",
      "word:conditioner\n",
      "word:conjunction\n",
      "word:temperature\n",
      "word:sensor\n",
      "word:Multi\n",
      "['space', 'heater', 'window', 'air', 'conditioner', 'conjunction', 'temperature', 'sensor', 'multi']\n",
      "analysing app description:  122\n",
      "word:Weather\n",
      "['weather']\n",
      "analysing app description:  123\n",
      "word:sensor\n",
      "['sensor']\n",
      "analysing app description:  124\n",
      "word:shed\n",
      "word:grill\n",
      "word:lawn\n",
      "word:tomorrow\n",
      "['shed', 'grill', 'lawn', 'tomorrow']\n",
      "analysing app description:  125\n",
      "word:house\n",
      "word:fan\n",
      "word:switch\n",
      "word:x\n",
      "word:temp\n",
      "word:Thermostat\n",
      "word not processed:  x\n",
      "['house', 'fan', 'switch', 'temp', 'thermostat']\n",
      "analysing app description:  126\n",
      "analysing app description:  127\n",
      "word:time\n",
      "word:day\n",
      "word:person\n",
      "word:home\n",
      "word:action\n",
      "['time', 'day', 'person', 'home', 'action']\n",
      "analysing app description:  128\n"
     ]
    }
   ],
   "source": [
    "set_of_keywords = []\n",
    "POS_accepted=[\"NN\"] # part of speech tags accepted ---> deleted: \"NNP\", \"NNPS\"\n",
    "\n",
    "for i in range(len(descriptions)):\n",
    "    keywords = []       # keywords found\n",
    "    keyword_vector = {} # dictionary keyword -> vector rappresentation\n",
    "    print(\"analysing app description: \",i)\n",
    "    des_analysed = nlp(descriptions[i]) # apply Stanford NLP to description\n",
    "    for sent in des_analysed.sentences:\n",
    "        for word in sent.words: # check each word of the description\n",
    "            if word.xpos in POS_accepted:\n",
    "                keywords_found = word.text.lower() # filter: to all lowercase words\n",
    "                if not keywords_found in keywords: # if not already save that word\n",
    "                    print(f\"word:{word.text}\")\n",
    "                    keywords.append(keywords_found) # add to the list of keywords\n",
    "    if len(keywords) > 0:\n",
    "        for i in range(len(keywords)):\n",
    "            try:\n",
    "                word = str(keywords[i])\n",
    "                if len(word) > 1:\n",
    "                    keyword_vector[word] = model[word] # using Word2Vec\n",
    "                else:\n",
    "                    print(\"word not processed: \",word)\n",
    "            except KeyError as err:\n",
    "                print(\"handling Error: \", err) # some words can not be processed by Word2Vec\n",
    "\n",
    "        similarity_matrix = np.ones((len(keyword_vector.keys()), len(keyword_vector.keys())))\n",
    "        similarity_matrix = similarity_matrix * 999\n",
    "        keyword_lsit = list(keyword_vector.keys())\n",
    "        print(keyword_lsit)\n",
    "        #print(similarity_matrix)\n",
    "        for key_x in range(len(keyword_vector.keys())):\n",
    "            for key_y in range(len(keyword_vector.keys())):\n",
    "                #print(\"check\",keywords[key_x], \" and \", keywords[key_y] )\n",
    "                if key_x != key_y:\n",
    "                    similarity_matrix[key_x][key_y] = (np.linalg.norm(keyword_vector[keyword_lsit[key_x]]-keyword_vector[keyword_lsit[key_y]]))\n",
    "        \n",
    "        #print(similarity_matrix)\n",
    "        aggregation_result = np.min(similarity_matrix, axis=0)\n",
    "        key1 = keyword_lsit[np.argmin(aggregation_result)]\n",
    "        key2 = keyword_lsit[np.argmin(similarity_matrix[np.argmin(aggregation_result)][:])]\n",
    "        if not key1 in set_of_keywords:\n",
    "            set_of_keywords.append(key1)\n",
    "        if not key2 in set_of_keywords:\n",
    "            set_of_keywords.append(key2)\n",
    "        \n",
    "#         keywords = list(keyword_vector.keys())\n",
    "#         vectors = []\n",
    "#         for key in keyword_vector.keys():\n",
    "#             vectors.append(keyword_vector[key])\n",
    "\n",
    "#         centroid = np.array(vectors).mean(axis=0) # axis=0 all vector 300x1\n",
    "#         #print(centroid)\n",
    "#         similarity = []\n",
    "#         for key in keyword_vector.keys():\n",
    "#             similarity.append(np.linalg.norm(centroid-keyword_vector[key]))\n",
    "#         print(\"win:\",keywords[np.argmin(similarity)])\n",
    "#         if not keywords[np.argmin(similarity)] in set_of_keywords:\n",
    "#             set_of_keywords.append(keywords[np.argmin(similarity)])\n",
    "            \n",
    "#set_of_keywords\n",
    "\n",
    "\n",
    "#aggregation_result = np.sum(similarity_matrix, axis=0)\n",
    "#set_of_keywords.append(keywords[np.argmin(aggregation_result)])\n",
    "    \n",
    "#set_of_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f871fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account',\n",
       " 'air',\n",
       " 'alarm',\n",
       " 'amount',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'app',\n",
       " 'area',\n",
       " 'arrival',\n",
       " 'bed',\n",
       " 'burst',\n",
       " 'button',\n",
       " 'case',\n",
       " 'change',\n",
       " 'chat',\n",
       " 'collection',\n",
       " 'color',\n",
       " 'contact',\n",
       " 'control',\n",
       " 'controller',\n",
       " 'cube',\n",
       " 'day',\n",
       " 'demonstration',\n",
       " 'departure',\n",
       " 'device',\n",
       " 'door',\n",
       " 'element',\n",
       " 'end',\n",
       " 'endpoint',\n",
       " 'energy',\n",
       " 'event',\n",
       " 'everything',\n",
       " 'garage',\n",
       " 'graph',\n",
       " 'home',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'hub',\n",
       " 'hue',\n",
       " 'humidity',\n",
       " 'input',\n",
       " 'jawbone',\n",
       " 'level',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lighting',\n",
       " 'location',\n",
       " 'mail',\n",
       " 'mailbox',\n",
       " 'manager',\n",
       " 'message',\n",
       " 'middle',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'money',\n",
       " 'mood',\n",
       " 'motion',\n",
       " 'movement',\n",
       " 'multi',\n",
       " 'night',\n",
       " 'notification',\n",
       " 'number',\n",
       " 'option',\n",
       " 'panel',\n",
       " 'panic',\n",
       " 'period',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'place',\n",
       " 'power',\n",
       " 'presence',\n",
       " 'push',\n",
       " 'region',\n",
       " 'report',\n",
       " 'row',\n",
       " 'schedule',\n",
       " 'sensor',\n",
       " 'service',\n",
       " 'set',\n",
       " 'setting',\n",
       " 'setup',\n",
       " 'shed',\n",
       " 'sleep',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'song',\n",
       " 'sound',\n",
       " 'space',\n",
       " 'speaker',\n",
       " 'state',\n",
       " 'station',\n",
       " 'status',\n",
       " 'step',\n",
       " 'sunrise',\n",
       " 'sunset',\n",
       " 'switch',\n",
       " 'system',\n",
       " 'test',\n",
       " 'text',\n",
       " 'thermostat',\n",
       " 'threshold',\n",
       " 'time',\n",
       " 'tomorrow',\n",
       " 'turn',\n",
       " 'unit',\n",
       " 'use',\n",
       " 'user',\n",
       " 'valve',\n",
       " 'waking',\n",
       " 'warning',\n",
       " 'weather',\n",
       " 'week']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_keywords.sort()\n",
    "set_of_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed50a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_keywords = []\n",
    "for i in range(len(set_of_keywords)):\n",
    "    np_keywords.append(model[set_of_keywords[i]])\n",
    "np_keywords = np.array(np_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61b481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot keywords:112, tot features:300\n"
     ]
    }
   ],
   "source": [
    "print(f\"tot keywords:{np_keywords.shape[0]}, tot features:{np_keywords.shape[1]}\") # check the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bf6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 91,  44,  56,  82,  69, 103,  99,  58,  35,  38,  65,  92,   2,\n",
       "       100, 105,  53])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the clustering algh\n",
    "n_cluster = 16 # by paper\n",
    "np.random.seed(1)\n",
    "initial_cluster_idx = np.random.choice(len(np_keywords), n_cluster, replace=False)\n",
    "initial_cluster_idx # initial random centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a049110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09130859,  0.08837891,  0.03881836, ...,  0.08447266,\n",
       "         0.09130859, -0.07421875],\n",
       "       [ 0.12988281,  0.17382812,  0.10302734, ...,  0.10009766,\n",
       "         0.19726562, -0.11865234],\n",
       "       [ 0.06884766,  0.05078125, -0.19140625, ..., -0.05395508,\n",
       "        -0.09521484,  0.2265625 ],\n",
       "       ...,\n",
       "       [ 0.0456543 , -0.21191406, -0.13964844, ..., -0.0480957 ,\n",
       "         0.13769531, -0.03198242],\n",
       "       [ 0.11279297, -0.13085938,  0.06689453, ..., -0.17285156,\n",
       "        -0.07910156,  0.05786133],\n",
       "       [ 0.24609375,  0.19628906, -0.17871094, ...,  0.13964844,\n",
       "        -0.0025177 ,  0.35742188]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_coordinate = np_keywords[initial_cluster_idx,:]\n",
    "centroid_coordinate # coordinate of initial ranfom centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a0f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.63590555, 3.46220146, 4.04119684, ..., 3.87171731, 3.21588726,\n",
       "        3.73691739],\n",
       "       [3.73552992, 3.13154992, 3.68121998, ..., 4.10377914, 3.03846004,\n",
       "        3.70603255],\n",
       "       [4.24413649, 3.90725089, 4.48389202, ..., 4.42399068, 3.9656758 ,\n",
       "        4.35699846],\n",
       "       ...,\n",
       "       [3.89322683, 3.4103483 , 4.12336569, ..., 4.16977659, 3.32904114,\n",
       "        4.1542562 ],\n",
       "       [4.07600827, 3.57203145, 4.4215931 , ..., 4.65120239, 3.62667309,\n",
       "        4.16018038],\n",
       "       [3.4021537 , 3.03228619, 3.64408251, ..., 3.60919999, 2.92530612,\n",
       "        3.63297197]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix = cdist(np_keywords, centroid_coordinate, 'euclidean') # calculate the distance of all keyword and centroids\n",
    "print(len(distance_matrix)) # cityblock is the Manhattan distance https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "print(distance_matrix.shape[1])\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2faf72ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 14, 12, 14,  5,  5, 14, 14,  5,  3,  5, 15,  5,  5, 14, 14,  1,\n",
       "       14,  4, 15,  5,  8, 14,  5, 14,  5, 11,  5, 14,  4,  5,  5, 14,  5,\n",
       "        5,  8,  5, 14,  9,  1, 14,  5, 13,  5,  1,  1, 14, 14, 14, 14, 14,\n",
       "        5, 14, 15,  5,  1,  2, 14,  7,  8, 14, 14, 14,  1,  5, 10, 14, 14,\n",
       "        5,  4, 14,  5,  5,  5,  5,  8,  1, 14,  5,  5, 14,  1,  3,  5,  5,\n",
       "        5, 14, 14, 14,  5,  8,  0, 11,  8,  5,  5, 14, 14, 14,  6, 13, 10,\n",
       "        5,  5, 14, 14, 14,  5,  3,  5,  5,  8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([np.argmin(i) for i in distance_matrix]) # set firts labels to all keyword in function of the distance\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c6428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/500\n",
      "1/500\n",
      "2/500\n",
      "Reached convergence at iteration nr 2\n"
     ]
    }
   ],
   "source": [
    "max_iter=500 # set max number of iteration \n",
    "for it in range(max_iter):\n",
    "    print(f\"{it}/{max_iter}\")\n",
    "    centroid_coordinate = []\n",
    "    for idx in range(n_cluster):\n",
    "        # Updating Centroids by taking mean of Cluster it belongs to\n",
    "        temp_cent = np_keywords[labels == idx].mean(axis=0) # axis=0 all vector 300x1\n",
    "        centroid_coordinate.append(temp_cent)\n",
    "\n",
    "    centroid_coordinate = np.vstack(centroid_coordinate)  # Updated Centroids\n",
    "    \n",
    "    distance_matrix = cdist(np_keywords, centroid_coordinate, 'euclidean') # recalculate the distance\n",
    "\n",
    "    old_labels = labels.copy()\n",
    "    labels = np.array([np.argmin(i) for i in distance_matrix])\n",
    "\n",
    "    # Check for convergence\n",
    "    if all(labels == old_labels):\n",
    "        print('Reached convergence at iteration nr', it)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a11ce6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5, 12, 14,  5,  5, 14, 14,  5,  3,  5, 15,  5,  5, 14, 14,  1,\n",
       "       14,  4, 15, 14,  8, 14,  5, 14,  5, 11,  5, 14,  4,  5,  5, 14,  5,\n",
       "        5,  8,  5, 14,  9,  1, 14,  5, 13,  5,  1,  1, 14, 14, 14, 14, 14,\n",
       "        5, 14, 15,  5,  1,  2, 14,  7,  8, 14, 14, 14,  1,  5, 10, 14, 14,\n",
       "        5,  4, 14,  5,  5,  5,  5,  8,  1, 14,  5,  5, 14,  1,  3,  5,  5,\n",
       "        5,  5, 14, 14,  5,  8,  0, 11,  8,  8,  5, 14, 14, 14,  6, 13, 10,\n",
       "        8,  5, 14, 14, 14,  5,  3,  5,  1,  8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels # display the clustering associated with each keyword (from 0 to 15 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc49a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: 'status'},\n",
       " 1: {0: 'color',\n",
       "  1: 'humidity',\n",
       "  2: 'light',\n",
       "  3: 'lighting',\n",
       "  4: 'mood',\n",
       "  5: 'panel',\n",
       "  6: 'sensor',\n",
       "  7: 'shed',\n",
       "  8: 'weather'},\n",
       " 2: {0: 'motion'},\n",
       " 3: {0: 'bed', 1: 'sleep', 2: 'waking'},\n",
       " 4: {0: 'control', 1: 'energy', 2: 'power'},\n",
       " 5: {0: 'account',\n",
       "  1: 'air',\n",
       "  2: 'anything',\n",
       "  3: 'anytime',\n",
       "  4: 'arrival',\n",
       "  5: 'burst',\n",
       "  6: 'case',\n",
       "  7: 'change',\n",
       "  8: 'departure',\n",
       "  9: 'door',\n",
       "  10: 'end',\n",
       "  11: 'event',\n",
       "  12: 'everything',\n",
       "  13: 'graph',\n",
       "  14: 'home',\n",
       "  15: 'house',\n",
       "  16: 'jawbone',\n",
       "  17: 'life',\n",
       "  18: 'middle',\n",
       "  19: 'money',\n",
       "  20: 'panic',\n",
       "  21: 'place',\n",
       "  22: 'push',\n",
       "  23: 'region',\n",
       "  24: 'report',\n",
       "  25: 'row',\n",
       "  26: 'set',\n",
       "  27: 'setting',\n",
       "  28: 'someone',\n",
       "  29: 'something',\n",
       "  30: 'song',\n",
       "  31: 'sound',\n",
       "  32: 'state',\n",
       "  33: 'switch',\n",
       "  34: 'turn',\n",
       "  35: 'valve',\n",
       "  36: 'warning'},\n",
       " 6: {0: 'thermostat'},\n",
       " 7: {0: 'multi'},\n",
       " 8: {0: 'day',\n",
       "  1: 'hour',\n",
       "  2: 'night',\n",
       "  3: 'schedule',\n",
       "  4: 'station',\n",
       "  5: 'sunrise',\n",
       "  6: 'sunset',\n",
       "  7: 'tomorrow',\n",
       "  8: 'week'},\n",
       " 9: {0: 'hue'},\n",
       " 10: {0: 'period', 1: 'time'},\n",
       " 11: {0: 'element', 1: 'step'},\n",
       " 12: {0: 'alarm'},\n",
       " 13: {0: 'level', 1: 'threshold'},\n",
       " 14: {0: 'amount',\n",
       "  1: 'app',\n",
       "  2: 'area',\n",
       "  3: 'chat',\n",
       "  4: 'collection',\n",
       "  5: 'contact',\n",
       "  6: 'cube',\n",
       "  7: 'demonstration',\n",
       "  8: 'device',\n",
       "  9: 'endpoint',\n",
       "  10: 'garage',\n",
       "  11: 'hub',\n",
       "  12: 'input',\n",
       "  13: 'location',\n",
       "  14: 'mail',\n",
       "  15: 'mailbox',\n",
       "  16: 'manager',\n",
       "  17: 'message',\n",
       "  18: 'mod',\n",
       "  19: 'movement',\n",
       "  20: 'notification',\n",
       "  21: 'number',\n",
       "  22: 'option',\n",
       "  23: 'person',\n",
       "  24: 'phone',\n",
       "  25: 'presence',\n",
       "  26: 'service',\n",
       "  27: 'setup',\n",
       "  28: 'space',\n",
       "  29: 'speaker',\n",
       "  30: 'system',\n",
       "  31: 'test',\n",
       "  32: 'text',\n",
       "  33: 'unit',\n",
       "  34: 'use',\n",
       "  35: 'user'},\n",
       " 15: {0: 'button', 1: 'controller', 2: 'mode'},\n",
       " 16: {},\n",
       " 17: {},\n",
       " 18: {},\n",
       " 19: {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save inside a dictionary the set of keyword correlated to each cluster\n",
    "cluster_result={0:{},1:{},2:{},3:{},4:{},5:{},6:{},7:{},8:{},9:{},10:{},11:{},12:{},13:{},14:{},15:{},16:{},17:{},18:{},19:{}}\n",
    "for i in range(len(labels)):\n",
    "    cluster_result[labels[i]][len(cluster_result[labels[i]])] = set_of_keywords[i]   \n",
    "\n",
    "cluster_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd271eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile = open(\"analysis_NEW/centroids.txt\",\"w\") # save it\n",
    "for i in range(len(centroid_coordinate)):\n",
    "               myFile.write(str(centroid_coordinate[i]))\n",
    "               myFile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a522ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords appartenenti al cluster 0: 1\n",
      "\n",
      "keywords appartenenti al cluster 1: 9\n",
      "\n",
      "keywords appartenenti al cluster 2: 1\n",
      "\n",
      "keywords appartenenti al cluster 3: 3\n",
      "\n",
      "keywords appartenenti al cluster 4: 3\n",
      "\n",
      "keywords appartenenti al cluster 5: 37\n",
      "\n",
      "keywords appartenenti al cluster 6: 1\n",
      "\n",
      "keywords appartenenti al cluster 7: 1\n",
      "\n",
      "keywords appartenenti al cluster 8: 9\n",
      "\n",
      "keywords appartenenti al cluster 9: 1\n",
      "\n",
      "keywords appartenenti al cluster 10: 2\n",
      "\n",
      "keywords appartenenti al cluster 11: 2\n",
      "\n",
      "keywords appartenenti al cluster 12: 1\n",
      "\n",
      "keywords appartenenti al cluster 13: 2\n",
      "\n",
      "keywords appartenenti al cluster 14: 36\n",
      "\n",
      "keywords appartenenti al cluster 15: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_cluster):\n",
    "    print(f\"keywords appartenenti al cluster {i}: {len(cluster_result[i])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b454d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile = open(\"analysis_NEW/cluster_result.txt\",\"w\") # save\n",
    "for i in range(n_cluster):\n",
    "    myFile.write(f\"\\ncluster {i}:(tot keywords found:{len(cluster_result[i])})\\n\")\n",
    "    myFile.write(f\"keyword of the cluster:\")\n",
    "    for j in range(len(cluster_result[i])):\n",
    "        myFile.write(f\" {cluster_result[i][j]}\")\n",
    "    \n",
    "    # the centroid coordinates it's not a real word because is a mean between other words\n",
    "    myFile.write(f\"\\ncentroid fund:{model.most_similar(centroid_coordinate[i])}\\n\")\n",
    "    myFile.write(f\"\")\n",
    "\n",
    "    \n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca88ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trovati cluster ottimi!! - analisi carta e penna dei risulatati\n",
    "physical_channel_centroids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8844f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_channel_centroids[\"Temperature\"] = np.array(centroid_coordinate[13])\n",
    "physical_channel_centroids[\"Humidity\"] = np.array(centroid_coordinate[12])\n",
    "physical_channel_centroids[\"Illumination\"] = np.array(centroid_coordinate[3])\n",
    "physical_channel_centroids[\"Location\"] = np.array(centroid_coordinate[6])\n",
    "physical_channel_centroids[\"Motion\"] = np.array(centroid_coordinate[14])\n",
    "physical_channel_centroids[\"Smoke\"] = np.array(centroid_coordinate[15])\n",
    "physical_channel_centroids[\"Leakage\"] = np.array(centroid_coordinate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_channel_centroids[\"Temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cluster centroids inside a JSON file :)\n",
    "myFile = open(\"analysis_NEW/physical_channel_2.JSON\",\"w\") # save\n",
    "myFile.write(\"{\\n\")\n",
    "for key in physical_channel_centroids.keys():\n",
    "    myFile.write(f\"\\\"{key}\\\":{repr(physical_channel_centroids[key])},\\n\")\n",
    "    \n",
    "myFile.write(\"}\")\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895bcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test aggiuntivi altro algoritmo di clustering **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters=16\n",
    "# Init estimator and fit it on the data\n",
    "sk_kmeans = KMeans(n_clusters=16, max_iter=max_iter).fit(np_keywords)\n",
    "\n",
    "# Get predicted labels and centroids\n",
    "sk_labels = sk_kmeans.labels_\n",
    "sk_centroids = sk_kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5381684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save inside a dictionary the set of keyword correlated to each cluster\n",
    "sk_cluster_result={0:{},1:{},2:{},3:{},4:{},5:{},6:{},7:{},8:{},9:{},10:{},11:{},12:{},13:{},14:{},15:{},16:{},17:{},18:{},19:{},\n",
    "                  20:{},21:{},22:{},23:{},24:{}}\n",
    "for i in range(len(np_keywords)):\n",
    "    sk_cluster_result[sk_labels[i]][len(sk_cluster_result[sk_labels[i]])]=key_list[i]   \n",
    "\n",
    "cluster_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0148a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myFile = open(\"analysis_NEW/sk_cluster_result.txt\",\"w\") # save\n",
    "for i in range(n_cluster):\n",
    "    myFile.write(f\"\\ncentroid cluster {i}:(tot keywords found:{len(sk_cluster_result[i])})\\n\")\n",
    "    myFile.write(f\"keyword of the cluster:\")\n",
    "    for j in range(len(sk_cluster_result[i])):\n",
    "        myFile.write(f\" {sk_cluster_result[i][j]}\")\n",
    "    \n",
    "    myFile.write(f\"\\ncentroid fund:{model.most_similar(sk_centroids[i])}\\n\")\n",
    "    myFile.write(f\"\")\n",
    "\n",
    "    \n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea095ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ef0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
